{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling \n",
    "\n",
    "#### Pakete laden\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, precision_recall_curve, roc_curve\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    " \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input: Bereinigte Daten von Data_Understanding_Preparation\n",
    "Einlesen aus csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir verwenden zunächst den unbereinigten Datensatz\n",
    "\n",
    "employee_data_raw = pd.read_pickle('../HR_Data_raw.pkl')\n",
    "employee_data = pd.read_pickle('../HR_Data_One_Hot_Encoded.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Überprüfen ob die Spalten und Daten wie erwartet bereinigt sind. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aufteilen der Daten in Zielvariable X und Attribute Y.\n",
    "X = employee_data.drop('Attrition', axis=1)\n",
    "y = employee_data.Attrition\n",
    "\n",
    "#Aufteilen der Daten in Test und Trainingsdaten.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es wird die Standardtestgröße von 25% gewhält. \n",
    "Da es sich im HR Datenset um ein unbalanciertes Datenset handeln, wird mithilfe von \"stratify\" sichergestellt, dass die Verteilung der Attrition Werte im Test und Trainingsdatenset nahezu gleich ist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stay = (y_train.value_counts().iloc[0] / y_train.shape)[0]\n",
    "leave = (y_train.value_counts().iloc[1] / y_train.shape)[0]\n",
    "\n",
    "print(\"===============TRAIN=================\")\n",
    "print(f\"Staying Rate: {stay * 100:.2f}%\")\n",
    "print(f\"Leaving Rate: {leave * 100 :.2f}%\")\n",
    "\n",
    "stay = (y_test.value_counts().iloc[0] / y_test.shape)[0]\n",
    "leave = (y_test.value_counts().iloc[1] / y_test.shape)[0]\n",
    "\n",
    "print(\"===============TEST=================\")\n",
    "print(f\"Staying Rate: {stay * 100:.2f}%\")\n",
    "print(f\"Leaving Rate: {leave * 100 :.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Evaluieren der verschiedenen Modelle\n",
    "def evaluate(model, X_train, X_test, y_train, y_test):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    print(\"TRAINIG RESULTS: \\n===============================\")\n",
    "    clf_report = pd.DataFrame(classification_report(y_train, y_train_pred, output_dict=True, zero_division=0))\n",
    "    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_train, y_train_pred)}\")\n",
    "    print(f\"ACCURACY SCORE:\\n{accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "    print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "\n",
    "    print(\"TESTING RESULTS: \\n===============================\")\n",
    "    clf_report = pd.DataFrame(classification_report(y_test, y_test_pred, output_dict=True, zero_division=0))\n",
    "    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_test, y_test_pred)}\")\n",
    "    print(f\"ACCURACY SCORE:\\n{accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "    print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Support Vector Machine (SVM) ist ein überwachter Lernalgorithmus, der versucht das Risiko von Overfitting zu verringern. Bei der SVM wird jedes Mitglied des Trainingsdatensatzes einer vor zwei Kategorien zugewiesen, sodass es sich um einen nicht-probabilistischen binären linearen Klassifikator handelt. Bei einer linearen Klassifikation werden die Eingabetrainingsdatenpunkte in einem Raum (Hyperplane) abgebildet, jeder mit einem anderen Klassenlabel, das durch eine klare Lücke voneinander getrennt ist. Neue Datenpunkte werden dann in denselben Raum abgebildet und als Teil einer Klasse vorhergesagt, je nachdem, auf welcher Seite der Lücke sie liegen. SVM kann aber auch nicht-lineare Klassifikationen durchführen. Nebst der Robustheit gegenüber Überanpassung liegt der Vorteil in der Effektivität in hochdimensionalen Räumen (also wenn die Anzahl der Merkmale größer als die Anzahl an Beobachtungen ist). Durch verschiedene Kernel-Funktionen (darunter linear, polynominal und sigmoid) sind SVMs flexibel auf verschiedene Datensätze und Problemtypen einsetzbar. Allerdings gestaltet sich die Modellauswahl mitunter durch das Hyperparameter-Tuning und die Kernel-Auswahl als komplex. Unter der Modellkomplexität leidet ebenfalls die Interpretierbarkeit (Cortes und Vapnik 1995)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen und trainieren des SVM Modells \n",
    "svm = SVC(kernel='linear', C=1.0, probability=True, random_state=2)\n",
    "svm.fit(X_train, y_train)\n",
    "evaluate(svm, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe von GridSearch wird eine geeignete Parameterkombination identifiziert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(random_state=2)\n",
    "\n",
    "param_grid = [\n",
    "    {'C': [0.1, 1, 6, 10], 'gamma': [0.001, 0.005, 0.01], 'kernel': ['linear']},\n",
    "]\n",
    "\n",
    "\n",
    "search = GridSearchCV(svm, param_grid=param_grid, scoring='roc_auc', cv=3, refit=True, verbose=1)\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei mehrmaligem Testen mit unterschiedlichen RandomStates wird deutlich, dass die geeigneten Parameterkombinationen stark voneinander abweichen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(**search.best_params_, probability=True)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "evaluate(svm, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualisierung der Modellperformance\n",
    "\n",
    "Die *ROC-Curve* (Receiver Operating Characteristic) ist ein Tool zur Bewertung der Leistung eines binären Klassifikationsmodells. Sie stellt die wahre positive Rate (True Positive Rate, TPR) gegenüber der falschen positiven Rate (False Positive Rate, FPR) dar, um die Trennschärfe des Modells bei verschiedenen Schwellenwerten zu visualisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_svm, tpr_svm, _ = roc_curve(y_test, svm.predict(X_test), pos_label='Yes')\n",
    "roc_auc_svm = roc_auc_score(y_test, svm.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotten der ROC-Kurve für SVM\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fpr_svm, tpr_svm, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_svm:0.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve SVM')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das Modell besser zu verstehen kann die Visualisierung mithilfe von SHAP und LIME durchgeführt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP-Explainer für das SVM-Modell erstellen\n",
    "explainer = shap.KernelExplainer(svm.predict_proba, X_train)\n",
    "\n",
    "# SHAP-Werte für die Testdaten berechnen\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# SHAP-Werte visualisieren\n",
    "shap.summary_plot(shap_values, X_test, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIME-Explainer erstellen\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, \n",
    "                                                   feature_names=X_train.columns, \n",
    "                                                   class_names=employee_data['No Attrition', 'Attrition'], \n",
    "                                                   discretize_continuous=True)\n",
    "\n",
    "# Eine einzelne Vorhersage erklären\n",
    "i = 0  # Index der zu erklärenden Instanz\n",
    "exp = explainer.explain_instance(X_test.iloc[i].values, \n",
    "                                 svm_clf.predict_proba, \n",
    "                                 num_features=4)\n",
    "\n",
    "# Visualisierung der Erklärung\n",
    "exp.show_in_notebook(show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vergleich der Methoden \n",
    "Im Folgenden werden die zuvor angewendeten Modelle SVM, XGBoost und Random Forest verglichen um zu bewerten, welches Modell die besten Ergebnisse liefert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotten der ROC-Kurven der verschiedenen Modelle\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# ROC-Kurve vor dem Tuning\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(fpr_svm, tpr_svm, color='darkorange', lw=2, label=f'ROC curve (area = {auc_svm:0.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve SVM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# ROC-Kurve XGBoost\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(xxx, xxx, color='darkorange', lw=2, label=f'ROC curve (area = {xxx:0.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC XGBoost')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# ROC-Kurve Random Forest\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(xxx, xxx, color='darkorange', lw=2, label=f'ROC curve (area = {xxx:0.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Random Forest')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
