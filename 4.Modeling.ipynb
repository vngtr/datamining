{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Modeling \n",
    "\n",
    "Mit der Data Preparation ist die Datenverarbeitung weitestgehend abgeschlossen. Allerdings bedarf es in Abhängigkeit von der Methode, weitere modellspezifische Datenvorbereitung. Die einzelnen Schritte werden an der jeweiligen Stelle vor dem Training kurz beschrieben.\n",
    "Die folgenden Modelle bieten sich für die vorliegende Klassifikationsaufgabe an und werden im Verlauf dieses Schrittes zunächst gerechnet, dann angepasst (u.a. mittels Parametertuning und Cross-Validation) sowie bewertet:  \n",
    "\n",
    "    1) Decision Tree & Random Forest  \n",
    "    2) xgBoost  \n",
    "    3) Suport Vector Machine  \n",
    "\n",
    "Die hierfür benötigten Pakete stammen aus der bereits aufgeführten Scikit-Learn Bibliothek (abgekürzt sklearn) und umfassen im Wesentlichen: \n",
    "\n",
    "*train_test_split*: Zur Überprüfung der Effektivität eines Machine-Learning-Modells wird der ursprüngliche Datensatz in ein Trainingsset und ein Testset aufgeteilt. Das Trainingsset dient dazu, das Modell mit einem Teil der Daten zu trainieren. Anschließend wird das Testset verwendet, um die Leistung des Modells auf einem separaten Teil der Daten zu evaluieren (Pedregosa et al. 2011). \n",
    "\n",
    "*accuracy_score*: Dient als Bewertungsmaß für die Leistung eines Klassifikationsmodells indem es den Anteil der korrekt vorhergesagter Werte ermittelt und diese mit den tatsächlichen Labels vergleicht (Pedregosa et al. 2011).\n",
    "\n",
    "*classification_report*: Erzeugt einen Bericht über die Leistung des Klassifikationsmodells und enthält Precision (Anzahl der positiv klassifizierten Instanzen, die tatsächlich positiv sind), Recall (wie gut erkennt das Modell positive Instanzen) und F1-Score (harmonischer Mittelwert von Recall und Precision) (Pedregosa et al. 2011).\n",
    "\n",
    "*confusion_matrix*: erstellt eine vier Felder Matrix und vergleicht die tatsächlichen und vorhergesagten Klassifikationen:\n",
    "\n",
    "|               | Vorhergesagt Positiv      | Vorhergesagt Negativ     |\n",
    "|---------------|--------------|-------------|\n",
    "| Tatsächlich Positiv       |   TP         |   FN        |\n",
    "| Tatsächlich Negativ       |   FP         |   TN        |\n",
    "\n",
    "- *True Positives (TP)*: Die Anzahl der tatsächlichen positiven Fälle, die korrekt als positiv vorhergesagt wurden.\n",
    "- *False Positives (FP)*: Die Anzahl der tatsächlichen negativen Fälle, die fälschlicherweise als positiv vorhergesagt wurden.\n",
    "- *True Negatives (TN)*: Die Anzahl der tatsächlichen negativen Fälle, die korrekt als negativ vorhergesagt wurden.\n",
    "- *False Negatives (FN)*: Die Anzahl der tatsächlichen positiven Fälle, die fälschlicherweise als negativ vorhergesagt wurden.  \n",
    "\n",
    "*DecisionTreeClassifier / RandomForestClassifier*: Sie dienen dazu, Entscheidungsbaum-Modelle für Klassifikationsaufgaben zu erstellen und zu trainieren (Pedregosa et al. 2011).\n",
    "\n",
    "*GridSearchCV / RandomizedSearchCV*: Sie werden zur Hyperparameter-Optimierung verwendet, indem sie systematisch verschiedene Kombinationen (innerhalb eines vordefinierten Rasters) von Hyperparametern testen und bewerten (Pedregosa et al. 2011).\n",
    "\n",
    "*plot_tree*: Zur grafischen Darstellung von Entscheidungsbäumen (Pedregosa et al. 2011).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, precision_recall_curve, roc_curve, precision_score, recall_score, f1_score,  mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    " \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import shap\n",
    "\n",
    "import math\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import sys\n",
    "\n",
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst werden die Daten als \"pickle\" eingelesen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Der Datensatz employee_data_transformed enthält den Datentyp \"object\", im Datensatz employee_data wurde der Datentyp \"object\" mittels One-Hot Encoding in Booleans umgewandelt\n",
    "\n",
    "employee_data_transformed = pd.read_pickle('../HR_Data_raw.pkl')\n",
    "employee_data = pd.read_pickle('../HR_Data_One_Hot_Encoded.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Überprüfen ob die Spalten und Daten wie erwartet bereinigt sind. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *5.1 Vorbereitung: Test-Train-Split, SMOTE & Feature Importance*\n",
    "\n",
    "Zunächst werden die Eingabevariablen bzw. Features im X-Array und die vorherzusagenden Labels, also die Zielvariable (\"Attrition\"), im Y-Array für alle Modelle einmalig zu Beginn definiert. Beim Split in Test- und Trainingsdaten im Verhältnis 25 zu 75 wird der *random_state* auf 42 gesetzt (als Anspielung auf *die ultimative Antwort auf die Frage nach dem Leben, dem Universum und allem*, basierend auf \"Per Anhalter durch die Galaxis\" von Douglas Adams). Der *random_state* sorgt für die Reproduzierbarkeit der Ergebnisse. Um das Problem der Datenungleichheit im Trainingsset innerhalb der Zielvariable (Yes: 237 vs. No: 1233) zu begegnen, wird SMOTE (Synthetic Minority Over-sampling Technique) angewandt. SMOTE generiert neue synthetische Beispiele für die Minderheitsklasse durch Interpolation zwischen bestehenden Instanzen im Merkmalsraum (Wang et al. 2006). Nach Anwendung dieses Verfahrens befinden sich in der Zielvariable des Trainingsdatensatz jeweils 913 Werte beider Klassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aufteilen der Daten in Zielvariable X und Attribute Y.\n",
    "X = employee_data.drop('Attrition', axis=1)\n",
    "y = employee_data.Attrition\n",
    "\n",
    "#Aufteilen der Daten in Test und Trainingsdaten.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwendung von SMOTE auf die Trainingsdaten\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Überprüfen der neuen Klassenverteilung\n",
    "print(\"Ursprüngliche Klassenverteilung:\\n\", y.value_counts())\n",
    "print(\"Neue Klassenverteilung:\\n\", pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Leistung der Klassifikationsmodelle auf die Trainings- und Testdaten zu evaluieren und für alle Modelle gleich zu bewerten, wird die Ausgabe der bereits geschilderten Bewertungsmetriken innerhalb der Funktion *evaluation* definiert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Evaluieren der verschiedenen Modelle\n",
    "def evaluation(clf, X_resampled, y_resampled, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_resampled)\n",
    "        clf_report = pd.DataFrame(classification_report(y_resampled, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_resampled, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_resampled, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vor der Anwendung des Decision Trees auf den vorbereiteten Datensatz, soll anhand des ursprünglichen Rohdatensatzes und der Feature Importance eines Entscheidungsbaums noch einmal überprüft werden, ob die im Data Preparation entfernten Variablen auch tatsächlich irrelevant sind. Die drei Variablen „StandardHours“, „EmployeeCount“ und „Over18“ tragen mit einer relativen Importance von 0.00 nicht zum Modell bei. Die beiden Einkommensvariablen „MonthlyRate“ und „HourlyRate“ weisen zwar eine relativ hohe Bedeutung für das Modell auf, stehen aber hinter dem „MonthlyIncome“ (auf Platz 2 mit einer relativen Importance von 0.09) und werden aufgrund der sehr hohen gemeinsamen Varianz und mangels Sinnhaftigkeit weiterhin ausgeschlossen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_data_raw = pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition.csv', sep=',')\n",
    "employee_data_raw.columns = employee_data_raw.columns.str.strip()\n",
    "\n",
    "# Datenvorbereitung\n",
    "categorical_col = []\n",
    "for column in employee_data_raw.columns:\n",
    "    if employee_data_raw[column].dtype == object:\n",
    "        categorical_col.append(column)\n",
    "for column in categorical_col:\n",
    "    employee_data_raw[column] = employee_data_raw[column].astype(\"category\").cat.codes\n",
    "employee_data_raw['Attrition'] = employee_data_raw['Attrition'].astype(\"category\").cat.codes\n",
    "\n",
    "# Datenaufteilung\n",
    "Xraw = employee_data_raw.drop('Attrition', axis=1).values  # Merkmale als NumPy-Array\n",
    "yraw = employee_data_raw['Attrition'].values               # Zielvariable als NumPy-Array\n",
    "Xraw_train, Xraw_test, yraw_train, yraw_test = train_test_split(Xraw, yraw, test_size=0.25, random_state=42)\n",
    "\n",
    "# Anwendung von SMOTE auf die Trainingsdaten\n",
    "smote = SMOTE(random_state=42)\n",
    "X_raw_resampled, y_raw_resampled = smote.fit_resample(Xraw_train, yraw_train)\n",
    "\n",
    "# Zählen der Anzahl der \"Yes\"-Labels (Attrition = 1) vor SMOTE\n",
    "num_yes_before = np.sum(y_train == 1)\n",
    "print(f\"Anzahl der 'Yes' (Attrition = 1) vor SMOTE: {num_yes_before}\")\n",
    "num_yes_after = np.sum(y_raw_resampled == 1)\n",
    "print(f\"Anzahl der 'Yes' (Attrition = 1) nach SMOTE: {num_yes_after}\")\n",
    "#Entscheidungsbaum\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_raw_resampled, y_raw_resampled)\n",
    "\n",
    "# Feature Wichtigkeit Roh-Daten ausgeben\n",
    "feature_importances = tree_clf.feature_importances_\n",
    "feature_names = employee_data_raw.drop('Attrition', axis=1).columns\n",
    "feature_importance_employee_data_raw = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importances:\\n\", feature_importance_employee_data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *5.2 Decision Tree (Entscheidungsbaum)*\n",
    "\n",
    "Ohne jegliche Modelloptimierung erreicht der Decision Tree eine Genauigkeit von 100% auf den Trainingsdaten und auf die Testdaten bereits einen Accuracy Score von 79.699%. Die meisten (90.70%) als Klasse 0 (keine Fluktuation) vorhergesagten Instanzen sind korrekt. Allerdings sind nur 28.00% der als Fluktuation vorhergesagten Labels richtig. Außerdem werden weniger als die Hälfte der tatsächlichen Instanzen dieser Klasse korrekt klassifiziert. Dementsprechend fällt auch die Konfusionsmatrix aus: 266 Instanzen korrekt als Klasse 0, aber 54 fälschlicherweise als Klasse 1 vorhergesagt. 27 Labels als Klasse 1 vorhergesagt, obwohl sie eigentlich der Klasse 0 angehören. Demgegenüber stehen 21 Instanzen, die korrekt als Fluktuation klassifiziert wurden.\n",
    "\n",
    "Die perfekte Leistung von 100% auf die Trainingsdaten kann ein Anzeichen von Overfitting sein und daher nicht gut auf unbekannte Daten generalisieren kann. Auf die Testdaten erzielt das Modell zwar insgesamt eine ordentliche Genauigkeit, aber die Leistung für das Label „Fluktuation“ ist suboptimal. Das Modell ist also nicht gut darin, die Minderheitsklasse zu erkennen. Möglicherweise kann ein anderes Modell hier bessere Werte erzielen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "evaluation(tree_clf, X_resampled,  y_resampled, X_test,y_test, train=True)\n",
    "evaluation(tree_clf, X_resampled,  y_resampled, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable „YearsInCurrentRole“ (Jahre in der aktuellen Position) hat die höchste relative Bedeutung (0.13) im Modell. Dies könnte dadurch erklärbar sein, dass dann die Hürden höher sind, das Unternehmen zu verlassen und andersherum. Auch das JobInvolvement (0.08), also Arbeitsengagement sowie das monatliche Einkommen (0.07) wirken sich -wenn auch geringer- auf die Klassifikation aus, was auch die Ergebnisse aus der Literaturrecherche sowie dem Data Understanding wiederspiegelt. Weitere wichtige Features mit einer mittleren relativen Wichtigkeit sind verheiratet (0.06) oder geschieden (0.05) sowie die beiden Zufriedenheitsskalen „EnvironmentSatisfacation“ (0.07) und JobSatisfaction (0.05). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Wichtigkeit bereinigte Daten ausgeben\n",
    "feature_importances = tree_clf.feature_importances_\n",
    "feature_names = employee_data.drop('Attrition', axis=1).columns\n",
    "feature_importance_employee_data = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importances:\\n\", feature_importance_employee_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem Entscheidungsbaum sind die wichtigsten Features tendenziell in den höheren Knoten des Baumes platziert. Je näher ein Feature an der Wurzel des Baumes erscheint und je öfter es verwendet wird, desto wichtiger ist es für die Entscheidungsfindung des Modells. Dies zeigt sich auch in der Grafik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entscheidungsbaum visualisieren\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree_clf, feature_names=feature_names, filled=True, fontsize=2)\n",
    "plt.title(\"Vollständiger Entscheidungsbaum\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausschnitt des Entscheidungsbaums visualisieren (z.B. nur bis Tiefe 3)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree_clf, feature_names=feature_names, filled=True, fontsize=10, max_depth=3)\n",
    "plt.title(\"Ausschnitt des Entscheidungsbaums (Tiefe 3)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beim Hyperparameter-Tuning werden zunächst die Werte manuell festgelegt.\n",
    "-\t*criterion: gini*: Bewertung des Splits mittels Gini-Index. *log_loss* basiert auf logistische Verlustmaße, *entropy* verwendet Entropie (Unsicherheit/Unreinheit).\n",
    "-\t*splitter: best*: Wählt den besten Split auf Basis von *criterion*, *random*: Wählt einen zufälligen Split.\n",
    "-\t*max_depth*: Maximale Tiefe des Baumes.\n",
    "-\t*min_samples_split*: Minimale Anzahl an erforderlichen Samples um einen Knoten weiter zu splitten.\n",
    "-\t*min_samples_lead*: Minimale Anzahl erforderlicher Samples, die in einem Blattknoten vorhanden sein müssen. \n",
    "\n",
    "Mit diesen Parametern sind die Accuracy Scores sowohl im Test- als auch im Trainingsdatensatz im Vergleich zum Entscheidungsbaum ohne Optimierung niedriger. Das Modell zeigt also in den Trainingsdaten keine perfekte Genauigkeit mehr. Dies deutet auf einen bessere Generalisierbarkeit und eine reduzierte Überanpassung hin. Nach wie vor hat das Modell Schwierigkeiten, auf den Testdaten die Klasse Fluktuation korrekt zu identifizieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manuelle Festlegung der Parameter\n",
    "manual_params = {\n",
    "    \"criterion\": \"gini\",        # \"gini\" oder \"entropy\" oder \"log_loss\"\n",
    "    \"splitter\": \"best\",         # \"best\" oder oder \"random\"\n",
    "    \"max_depth\": 10,            # Wertebereich ab 1\n",
    "    \"min_samples_split\": 2,     # Wertebereich ab 2\n",
    "    \"min_samples_leaf\": 2       # Wertebereich ab 1\n",
    "}\n",
    "\n",
    "# Entscheidung für das Modell mit den festgelegten Parametern\n",
    "tree_clf = DecisionTreeClassifier(random_state=42, **manual_params)\n",
    "tree_clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "evaluation(tree_clf, X_resampled, y_resampled, X_test, y_test, train=True)\n",
    "evaluation(tree_clf, X_resampled, y_resampled, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als weiterer Validierungsansatz soll Grid Search als bereits beschriebene Methode zur Parameteroptimierung angewandt werden. Insgesamt wurden 19494 verschiedene Parameterkombinationen getestet, was zu 97470 Trainingsvorgängen geführt hat. Die identifizierten Parameter deuten darauf hin, dass ein sehr einfacher Entscheidungsbaum mit maximaler Tiefe von 1 (ein Stumpf) die besten Ergebnisse während der Cross-Validation erzielt hat. Ein Baum mit dieser Konfiguration ist extrem einfach und trifft Entscheidungen basierend auf nur einem Merkmal. Dies hat allerdings zur Folge, dass der Entscheidungsbaum zwar nicht überanpasst, aber verfehlt dafür auch viele positive Instanzen (Fluktuation). Daraus lässt sich schließen, dass ein extrem einfacher Entscheidungsbaum nicht ausreichen leistungsfähig ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"criterion\":(\"gini\", \"entropy\", \"log_loss\"), \n",
    "    \"splitter\":(\"best\", \"random\"), \n",
    "    \"max_depth\":(list(range(1, 20))), \n",
    "    \"min_samples_split\":[2, 3, 4, 5, 6, 7, 8, 9, 10], \n",
    "    \"min_samples_leaf\":list(range(1, 20)), \n",
    "}\n",
    "\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_cv = GridSearchCV(\n",
    "    tree_clf, \n",
    "    params, \n",
    "    scoring=\"f1\", \n",
    "    n_jobs=-1, \n",
    "    verbose=1, \n",
    "    cv=5\n",
    ")\n",
    "\n",
    "tree_cv.fit(X_resampled, y_resampled)\n",
    "best_params = tree_cv.best_params_\n",
    "print(f\"Best paramters: {best_params})\")\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(**best_params)\n",
    "tree_clf.fit(X_resampled, y_resampled)\n",
    "evaluation(tree_clf, X_resampled, y_resampled, X_test, y_test, train=True)\n",
    "evaluation(tree_clf, X_resampled, y_resampled, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *5.3 Random Forest*\n",
    "\n",
    "Wie beim Entscheidungsbaum folgt zunächst die Anwendung des Random Forest ohne Parametertuning. Die Trainingsergebnisse weisen mit 65.66% eine moderate Genauigkeit (Accuracy Score) auf und scheint deshalb nicht in der Lage, die Labels (v.a. die Minderheitsklasse „Yes“) korrekt zu klassifizieren. Die Genauigkeit bei den Testdaten ist mit 72.83% höher als auf den Trainingsdaten und weist auf eine suboptimale Balance zwischen den Klassen hin. Auch hier zeigen die Bewertungsmetriken, wie Beispielsweise der Recall von 25.00%, dass das Modell mit sehr Yes-Instanzen verpasst. Nur 12 positive Labels wurden richtig klassifiziert, demgegenüber stehen 36 positive Labels, die fälschlicherweise als „No“ vorhergesagt wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "rf_clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "evaluation(tree_clf, X_resampled, y_resampled, X_test, y_test, train=True)\n",
    "evaluation(tree_clf, X_resampled, y_resampled, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrahieren der Feature Importance\n",
    "feature_importances = rf_clf.feature_importances_\n",
    "features = X_resampled.columns\n",
    "\n",
    "# Erstellen eines DataFrames für die Darstellung\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "\n",
    "# Sortieren nach Wichtigkeit\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Visualisierung der Feature Importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.title('Feature Importance - Random Forest')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstes wird die Hyperparameter-Optimierung mithilfe von Random Search durchgeführt.*RandomizedSearchCV* verwendet Kreuzvalidierung und eine feste Anzahl von Parameterwerten aus angegebenen Verteilungen (durch Parameter *n_inter* definiert) Die Vorteile dieser Methode liegen in der Effizienz und Flexibilität, insbesondere wenn der Suchraum groß und Ressourcen begrenzt sind (Pedregosa et al. 2011). \n",
    "\n",
    "-\t*n_estimators*: Anzahl der Bäume (hier Bereich von 200 bis 2000)\n",
    "-\t*min_weight_fraction_leaf*: Der minimale gewichtete Anteil der Gesamtsumme der Gewichte (aller Eingabestichproben), der an einem Blattknoten liegen muss.\n",
    "-\t*max_features*: Die Anzahl der Merkmale, die bei der Suche nach dem besten Split berücksichtigt werden sollen\n",
    "-\t*max_features*: Berücksichtigte Anzahl der Merkmale bei der Suche(*auto*: alle Features vs. *sqrt“: Wurzel der Gesamtzahl an Features)\n",
    "-\t*oob_score*: Ob Out-of-Bag-Stichproben verwendet werden sollen, um die Generalisierungsgenauigkeit zu schätzen.\n",
    "-\t*bootstrap*: *True* oder *False* ob Bootstrap-Sampling verwendet werden soll\n",
    "-\t*n_jobs*: hier werden alle verfügbaren Prozessoren und Paralellisierung verwendet\n",
    "\n",
    "Die Kombinationen aus dem definierten Parameterbereich werden mit 5-facher Kreuzvalidierung und auf Basis des F1-Score (besonders nützlich, wenn Klassen unausgewogen) bewertet. Der optimierte Random Forest arbeitet mit 400 Entscheidungsbäumen, die Tiefe jedes Baumes ist auf maximal 30 begrenzt. \n",
    "\n",
    "Sowohl die Trainingsergebnisse als auch Testergebnisse zeigen im Vergleich zum Modell ohne Parametertuning keine Verbesserung der Leistung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {\n",
    "    'n_estimators': n_estimators, \n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth, \n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf, \n",
    "    'bootstrap': bootstrap\n",
    "}\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_cv = RandomizedSearchCV(\n",
    "    estimator=rf_clf, \n",
    "    scoring='f1',\n",
    "    param_distributions=random_grid, \n",
    "    n_iter=200, \n",
    "    cv=5, \n",
    "    verbose=1, \n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_cv.fit(X_resampled, y_resampled)\n",
    "rf_best_params = rf_cv.best_params_\n",
    "print(f\"Best paramters: {rf_best_params})\")\n",
    "\n",
    "rf_clf = RandomForestClassifier(**rf_best_params)\n",
    "rf_clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "evaluation(tree_clf, X_resampled, y_resampled, X_test, y_test, train=True)\n",
    "evaluation(tree_clf, X_resampled, y_resampled, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mittels der ROC-Kurve (Receiver Operating Characteristic) kann die Leistung von Klassifikationsmodelle visuell beurteilt werden. Indem sie die TPR (True Positive Rate) gegen die FÜR (Fals Positive Rate) aufträgt. Die Fläche unter der Kurve (AUC, bzw. Area Under the Curve) stellt die Fähigkeit eines Modells zur Unterscheidung dar, ob eine spezifische Bedingung vorhanden ist oder nicht. Ein AUC von 0,5 repräsentiert einen Test ohne Unterscheidungsfähigkeit (d. h., nicht besser als Zufall), während eine AUC von 1,0 einen Test mit perfekter Unterscheidung darstellt (Hoo et al. 2017). Im vorliegenden Fall deutet der AUC von 0.74 darauf hin, dass das Modell eine deutlich bessere Leistung als ein Zufallsmodell aufweist, hat jedoch Raum für Verbesserungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnen der ROC-Kurve und AUC für den RandomForestClassifier\n",
    "y_prob_rf = rf_clf.predict_proba(X_test)[:, 1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_prob_rf)\n",
    "\n",
    "# Plotten der ROC-Kurve für RandomForestClassifier\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fpr_rf, tpr_rf, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_rf:0.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - RandomForestClassifier')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *5.4 XGBoost*\n",
    "\n",
    "Zur Lösung der Klassifikationsaufgabe mittels XGBoost ist müssen die Labels in numerischer Form (binär 0 und 1) vorliegen und zunächst in den Pandas-Datentyp „category“ umgewandelt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen und Trainieren des XGBoost Modells\n",
    "\n",
    "# 1. Zielvariable in numerische Codes umwandeln (Yes --> 1, No --> 0)\n",
    "if y_resampled.dtype == 'object':\n",
    "    y_resampled = y_resampled.astype('category')\n",
    "    y_resampled = y_resampled.cat.codes\n",
    "\n",
    "if y_test.dtype == 'object':\n",
    "    y_test = y_test.astype('category')\n",
    "    y_test = y_test.cat.codes\n",
    "\n",
    "if y.dtype == 'object':\n",
    "    y = y.astype('category')\n",
    "    y = y.cat.codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im ersten Schritt werden lediglich die für die Berechnung des Modells nötigen Parameter mit Standardwerten gesetzt:\n",
    "\n",
    "- *objective*: Hier binäres Klassifikationsproblem mit einer logistischen Regression.\n",
    "- *max_depth*: Maximale Tiefe jedes Entscheidungsbaum. Ein höherer Wert ermöglich komplexere Werte (Achtung: Overfitting).\n",
    "- *learning_rate*: legt die Lernrate fest und steuert die Schrittweite des Gradientabstiegs. Ziel ist das Finden der optimalen Werte der Modellparameter zur Minimierung der Loss Function (Misst Fehler zwischen vorhergesagten und tatsächlichen Werten, z.B. Mean Squared Error bei linearen Regression oder Log-Loss bei binären Klassifikation). Ein niedriger Werte macht Modell robust ggü. Overfitting (Achtung: mehr Iterationen nötig).\n",
    "- \"n_estimators\": Anzahl der Boosting-Runden. Jede Boosting-Runde (sequenzielles Training) fügt neuen Entscheidungsbaum hinzu und korrigiert die Fehler (Residuen) des vorherigen Baumes. Idee: Kombination vieler schwacher Modelle ergibt starkes Lernmodell.\n",
    "- *\"eval_metric\"*: Metrik zur Evaluierung des Modells. \"logloss\" steht für logarithmischer Verlust (Logarithmic Loss) und bewertet wie gut das Klassifikationsmodell Wahrscheinlichkeiten für die Klassen vorhersagt. Hier *logloss* als Evaluationsmetrik um die Leistung des Modells während des Trainings zu bewerten (Ziel: Minimierung des logarithmischen Verlustes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen und Trainieren des XGBoost-Modells mit XGBClassifier\n",
    "xgb_model = XGBClassifier(objective='binary:logistic', max_depth=6, learning_rate=0.3, n_estimators=100, eval_metric='logloss')\n",
    "# xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Vorhersagen mit dem Modell\n",
    "xgb_preds = xgb_model.predict(X_test)\n",
    "xgb_y_pred = (xgb_preds > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ergebnisse zeigen ein Trainingsresultat von 100% und somit eine perfekte Leistung. Auch hier ist Achtung vor Overfitting geboten. Mit einem Accuracy Score von 86.41% zeigt sich zwar eine signifikante Verschlechterung im Vergleich zu den Trainingsresultaten, aber die Genauigkeit ist immer noch hoch. Allerdings implizieren die Resultate auch bei diesem Modell eine geringere Präzision (47.37%) bei der Identifizierung bzw. Klassifikation der Minderheitsklasse (Fluktuation). Insgesamt wurden 300 Werte der Klasse 0 (keine Fluktuation) korrekt vorhergesagt und 20 fälschlicherweise als Klasse 0 klassifiziert (obwohl sie eigentlich der Klasse 1 entsprechen).Bei 30 Werten wiederum hat das Modell angenommen, dass sie der Klasse 0 angehören wobei es sich tatsächlich um Personen handelt, die das Unternehmen verlassen (Klasse 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, xgb_y_pred)\n",
    "plt.figure(figsize=(4.5, 3))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Stay', 'Quit'], yticklabels=['Stay', 'Quit'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(xgb_model, X_resampled, y_resampled, X_test, y_test, train=True )\n",
    "evaluation(xgb_model, X_resampled, y_resampled, X_test, y_test, train=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3 Hyperparameter Tuning\n",
    "\n",
    "Mit Hilfe von GridSearchCV kann aus einer Auswahl von Parametern die ideale Kombination ermittelt werden. \n",
    "Durch Verwendung von RandomSearchCV kann durch die Festlegung von Iterationen eine zufällig ideale Parameterkombination ermittelt werden.\n",
    "\n",
    "- *max_depth:* Steuert, wie tief jeder einzelne Entscheidungsbaum wachsen kann. Größere Werte können zu komplexeren Modellen führen.\n",
    "- *learning_rate (eta):* Kleinere Werte machen das Training langsamer, aber stabiler. Ein niedrigerer Wert erfordert oft mehr n_estimators.\n",
    "- *n_estimators:* Gibt an, wie viele Bäume im Modell trainiert werden. Mehr Bäume können zu besseren Modellen führen, aber auch die Rechenzeit erhöhen.\n",
    "- *subsample:* Der Anteil der Trainingsdaten, die für jede Boosting-Runde zufällig ausgewählt werden. Reduziert Overfitting, Werte zwischen 0.5 und 1.0 sind üblich.\n",
    "- *colsample_bytree:* Der Anteil der Merkmale, die für das Training jedes Baumes zufällig ausgewählt werden. Reduziert Overfitting, indem es die Vielfalt der Bäume erhöht. Werte zwischen 0.5 und 1.0 sind üblich.\n",
    "- *reg_alpha (alpha):* L1-Regularisierungsterm, der eine Strafe für die Summe der absoluten Werte der Koeffizienten hinzufügt. Fördert Sparsamkeit im Modell, indem es einige Koeffizienten auf genau Null setzt, was effektiv einer Feature-Auswahl entspricht und Overfitting reduziert.\n",
    "- *reg_lambda (lambda):* L2-Regularisierungsterm, der eine Strafe für die Summe der Quadrate der Koeffizienten hinzufügt. Stabilisiert das Modell, indem es alle Koeffizienten schrumpft, um Überanpassung zu reduzieren, ohne sie auf Null zu setzen, was zu einem glatteren und weniger komplexen Modell führt.\n",
    "- *gamma:* Mindesteste Verlustreduktion, die erforderlich ist, um eine Baumaufspaltung durchzuführen. Höhere Werte führen dazu, dass weniger Splits durchgeführt werden, was zu einfacheren und weniger overfitted Modellen führt.\n",
    "\n",
    "Wie im Data Understanding bereits festgestellt wurde, ist die Zielvariable \"Attrition\" unausgeglichen ist. 1.233 (84%) Mitarbeitende haben das Unternehmen nicht verlassen, während nur 237 (16%) gegangen sind. XGBoost hat einen speziellen Parameter scale_pos_weight für unausgeglichene Klassen.\n",
    "- *scale_pos_weight:* Kontrolliert das  Gleichgewicht zwischen positiven und negativen Werten. Der Wert wird verwendet, um den Gradienten für die positive Klasse zu skalieren. Dies hat zur Folge, dass das Modell beim Training der positiven Klasse Skalierungsfehler macht und das Modell dazu ermutigt, diese zu stark zu korrigieren. Dies kann wiederum dazu beitragen, dass das Modell eine bessere Leistung erzielt, wenn es Vorhersagen für die positive Klasse trifft. Wenn es zu weit geht, kann es dazu führen, dass das Modell die positive Klasse besser vorhersagt, was jedoch zu einer schlechteren Leistung der negativen Klasse oder beider Klassen führt. Ein typischer Wert wäre sum(negative instances) / sum(positive instances).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Search: Definiere Parametergrenzen\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.1, 0.5),\n",
    "    'subsample': uniform(0, 0.8),\n",
    "    'colsample_bytree': uniform(0, 1),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(0, 1),\n",
    "    'scale_pos_weight': randint(1,50)\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV starten, n_iter gibt an, wieviele Iterationen durchgeführt werden\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit\n",
    "random_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "print(f\"Best Parameter: {random_search.best_params_}\")\n",
    "print(f\"Best Score: {random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search: Definiere Parameter, je mehr Parameter betrachtet werden sollen, desto länger dauert die Suche\n",
    "# Daher werden hier nicht alle Variablen betrachtet \n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [5, 7, 9],\n",
    "    'learning_rate': [0.1, 0.2, 0.3],\n",
    "    'n_estimators': [80, 100, 120],\n",
    "    'subsample': [0.4, 0.6, 0.8],\n",
    "    'colsample_bytree':[0.1, 0.2, 0.3],\n",
    "    'scale_pos_weight' :[4, 6, 8]\n",
    "    #'reg_alpha': [0, 0.01, 0.1, 1],\n",
    "    #'reg_lambda': [0, 0.01, 0.1, 1],\n",
    "    # 'gamma': [0, 0.1, 0.5, 1]\n",
    "\n",
    "}\n",
    "\n",
    "# Grid Search durchführen\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=3)\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "print(f\"Best Parameter: {grid_search.best_params_}, BEst Score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen und Trainieren des XGBoost-Modells mit angepassten Parametern\n",
    "xgb_model = XGBClassifier(objective='binary:logistic',\n",
    "                          max_depth=7, \n",
    "                          learning_rate=0.2, \n",
    "                          n_estimators=120,\n",
    "                          subsample=0.6,\n",
    "                          colsample_bytree=0.2,\n",
    "                          scale_pos_weight=6, \n",
    "                          eval_metric='logloss')\n",
    "# xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Vorhersagen mit dem Modell\n",
    "xgb_preds = xgb_model.predict(X_test)\n",
    "xgb_y_pred = (xgb_preds > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, xgb_y_pred)\n",
    "plt.figure(figsize=(4.5, 3))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Stay', 'Quit'], yticklabels=['Stay', 'Quit'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je höher der Parameter scale_pos_weight gesetzt wird, um so mehr verbessert sich die Vorhersage für die positive Klasse. Trotz eines relativ hohen scale_pos_weight, ist die Vorhersagegüte für die positive Klasse (Quit) weiterhin nicht gut. Im Testdatensatz wurde nur knapp die Hälfte der Personen, die das Unternehmen tatsächlich verlassen korrekt vorhergesagt. Bei etwas mehr als der Hälfte wurde hingegen vorhergesagt, dass sie das Unternehmen nicht verlassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(xgb_model, X_resampled, y_resampled, X_test, y_test, train=True )\n",
    "evaluation(xgb_model, X_resampled, y_resampled, X_test, y_test, train=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch die angepasste Parameterkonfigurationen hat sich der Accuracy Score zwar von 86,41 % auf 83,15 % verschlechtert. Allerdings wurde der Recall-Score (misst die Fähigkeit, alle positiven Fälle zu finden (Verhältnis positiver Vorhersagen zu tatsächlich positive Werten)) von 37,5 % auf 47,9 % verbessert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4 Visualisierung der Modellperformance\n",
    "\n",
    "Die *ROC-Curve* (Receiver Operating Characteristic) ist ein Tool zur Bewertung der Leistung eines binären Klassifikationsmodells. Sie stellt die wahre positive Rate (True Positive Rate, TPR) gegenüber der falschen positiven Rate (False Positive Rate, FPR) dar, um die Trennschärfe des Modells bei verschiedenen Schwellenwerten zu visualisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnen der FPR, TPR und AUC\n",
    "fpr_xgb_model, tpr_xgb_model, _ = roc_curve(y_test, xgb_preds)\n",
    "roc_auc_xgb_model = roc_auc_score(y_test, xgb_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotten der ROC-Kurve für XGBoost\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fpr_xgb_model, tpr_xgb_model, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_xgb_model:0.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - XGBoost')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.5 Kreuzvalidierung\n",
    "\n",
    "Mit Kreuzvalidierung kann geprüft werden, wie gut ein Modell auf neue Daten angewendet werden kann. Dafür wird das Modell k-mal trainiert mit unterschiedlich großen Teilmengen. Die Modelleistung wird für jeden Durchlauf gemessen und ein Durchschnitt berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kreuzvalidierung\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "cross_val_results = cross_val_score(xgb.XGBClassifier(objective='binary:logistic',\n",
    "                          max_depth=7, \n",
    "                          learning_rate=0.2, \n",
    "                          n_estimators=120,\n",
    "                          subsample=0.6,\n",
    "                          colsample_bytree=0.2,\n",
    "                          scale_pos_weight=6, \n",
    "                          eval_metric='logloss'), X, y, cv=kfold, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy: {cross_val_results.mean()} +/- {cross_val_results.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.6 Vergleich Modell-Performance mit Daten im Originalformat vs. bereinigte Daten (One-Hot-Encoding)\n",
    "\n",
    "Verbessert sich die ROC-Curve, wenn XGBoost auf den Originaldaten (Datentyp Object, der für XGBoost in kategoriale Variablen umgewandelt wird) anstatt auf den mittels One-Hot Encoding bereinigten Daten ausgeführt wird?\n",
    "\n",
    "Hierfür wird der Datensatz employee_data_transformed benötigt. Dieser wird auf die gleiche Weise aufgeteilt in Trainings- und Testdaten wie der Datensatz employee_data (s.o.). Außerdem wird auch in diesem Datensatz mitttels SMOTE eine Gleichgewichtung der Zielvariablen erzeugt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datenvorbereitung\n",
    "categorical_col = []\n",
    "for column in employee_data_transformed.columns:\n",
    "    if employee_data_transformed[column].dtype == object:\n",
    "        categorical_col.append(column)\n",
    "for column in categorical_col:\n",
    "    employee_data_transformed[column] = employee_data_transformed[column].astype(\"category\").cat.codes\n",
    "employee_data_transformed['Attrition'] = employee_data_transformed['Attrition'].astype(\"category\").cat.codes\n",
    "\n",
    "#Aufteilen der Daten in Zielvariable X_2 und Attribute y_2.\n",
    "X_2 = employee_data_transformed.drop('Attrition', axis=1).values  # Merkmale als NumPy-Array\n",
    "y_2 = employee_data_transformed['Attrition'].values               # Zielvariable als NumPy-Array\n",
    "\n",
    "#Aufteilen der Daten in Test und Trainingsdaten.\n",
    "X_2_train, X_2_test, y_2_train, y_2_test = train_test_split(X_2, y_2, test_size=0.25, random_state=42)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_2_resampled, y_2_resampled = smote.fit_resample(X_2_train, y_2_train)\n",
    "\n",
    "# Zählen der Anzahl der \"Yes\"-Labels (Attrition = 1) vor SMOTE\n",
    "num_yes_before = np.sum(y_2_train == 1)\n",
    "print(f\"Anzahl der 'Yes' (Attrition = 1) vor SMOTE: {num_yes_before}\")\n",
    "num_yes_after = np.sum(y_2_resampled == 1)\n",
    "print(f\"Anzahl der 'Yes' (Attrition = 1) nach SMOTE: {num_yes_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = employee_data_transformed.drop('Attrition', axis=1) # Zielvariable entfernen\n",
    "y_2 = employee_data_transformed['Attrition']  # 'Attrition' Spalte als Series\n",
    "\n",
    "# Train-Test-Split durchführen\n",
    "X_2_train, X_2_test, y_2_train, y_2_test = train_test_split(X_2, y_2, test_size=0.25, random_state=42)\n",
    "\n",
    "# Textfeatures in Kategorien umwandeln\n",
    "categories = X_2_train.select_dtypes(include=object).columns.tolist()\n",
    "for col in categories:\n",
    "    X_2_train[col] = X_2_train[col].astype('category')\n",
    "    X_2_test[col] = X_2_test[col].astype('category')\n",
    "\n",
    "# Labels in numerische Codes umwandeln\n",
    "if y_2_train.dtype == 'object':\n",
    "    y_2_train = y_2_train.astype('category')\n",
    "    y_2_train = y_2_train.cat.codes\n",
    "\n",
    "if y_2_test.dtype == 'object':\n",
    "    y_2_test = y_2_test.astype('category')\n",
    "    y_2_test = y_2_test.cat.codes\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_2_resampled, y_2_resampled = smote.fit_resample(X_2_train, y_2_train)\n",
    "\n",
    "# Zählen der Anzahl der \"Yes\"-Labels (Attrition = 1) vor SMOTE\n",
    "num_yes_before = np.sum(y_2_train == 1)\n",
    "print(f\"Anzahl der 'Yes' (Attrition = 1) vor SMOTE: {num_yes_before}\")\n",
    "num_yes_after = np.sum(y_2_resampled == 1)\n",
    "print(f\"Anzahl der 'Yes' (Attrition = 1) nach SMOTE: {num_yes_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen der DMatrix\n",
    "# DMatrix ist eine spezielle Datenstruktur, die von XGBoost verwendet wird.\n",
    "# \"enable_categorial=True\" ermöglich die Verarbeitung kategorialer Daten\n",
    "\n",
    "dtrain_reg = xgb.DMatrix(X_2_resampled, y_2_resampled, enable_categorical=True)\n",
    "dtest_reg = xgb.DMatrix(X_2_test, y_2_test, enable_categorical=True)\n",
    "\n",
    "# Modell trainieren\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 7,\n",
    "    'eta': 0.2,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree':0.2,\n",
    "    'scale_pos_weight':6,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "xgb_model_2 = xgb.train(params, dtrain_reg, num_boost_round=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen\n",
    "y_pred_prob_2 = xgb_model_2.predict(dtest_reg)\n",
    "y_pred_2 = (y_pred_prob_2 > 0.5).astype(int)\n",
    "\n",
    "\n",
    "# Genauigkeit berechnen\n",
    "accuracy = accuracy_score(y_2_test, y_pred_2)\n",
    "mse = mean_squared_error(y_2_test, y_pred_prob_2)\n",
    "rmse = np.sqrt(mse)\n",
    "auc = roc_auc_score(y_2_test, y_pred_prob_2) \n",
    "fpr_xgb_model_2, tpr_xgb_model_2, _ = roc_curve(y_2_test, y_pred_prob_2)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"mse: {mse}\")\n",
    "print(f\"rmse: {rmse}\")\n",
    "print(f\"Area under Curve: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotten der ROC-Kurve für XGBoost\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fpr_xgb_model, tpr_xgb_model, color='darkorange', lw=2, label=f'ROC curve encoded (area = {roc_auc_xgb_model:0.4f})')\n",
    "plt.plot(fpr_xgb_model_2, tpr_xgb_model_2, color='darkgreen', lw=2, label=f'ROC curve original (area = {auc:0.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - XGBoost')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.7 Visualisierung der Feature Importance und des Entscheidungsbaums\n",
    "\n",
    "Der Feature Importance Plot berechnet, wie häufig das Feature verwendet wurde, um Entscheidungsbäume im Modell aufzuteilen. Nachfolgend wird die unterschiedliche Gewichtung der Features in Abhängigkeit der zugrunde liegenden Daten (Encoded oder original) dargestellt.\n",
    "\n",
    "EmployeeNumber und Monthly Income sind in beiden Fällen sehr wichtig für die Aufteilung der Entscheidungsbäume. Beim Encoded Datensatz führt mit Abstand das MonthlyIncome, beim Original Datensatz mit Abstand die EmployeeNumber das Ranking an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb.plot_importance(xgb_model, importance_type=\"weight\", max_num_features =10, title='Feature Importance - Encoded Data')\n",
    "plt.show()\n",
    "\n",
    "xgb.plot_importance(xgb_model_2, importance_type=\"weight\", max_num_features =10, title='Feature Importance - Original Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Entscheidungsregeln und die Struktur der Bäume besser zu verstehen, kann man sich diese grafisch darstellen lassen. Bei einer maximalen Tiefe von 7 wird der Baum allerdings schon sehr unübersichtlich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot des Entscheidungsbaumes\n",
    "fig, ax = plt.subplots(figsize=(80,50)) \n",
    "xgb.plot_tree(xgb_model, num_trees=0, rankdir = 'LR',  ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Support Vector Machine (SVM) ist ein überwachter Lernalgorithmus, der versucht das Risiko von Overfitting zu verringern. Bei der SVM wird jedes Mitglied des Trainingsdatensatzes einer vor zwei Kategorien zugewiesen, sodass es sich um einen nicht-probabilistischen binären linearen Klassifikator handelt. Bei einer linearen Klassifikation werden die Eingabetrainingsdatenpunkte in einem Raum (Hyperplane) abgebildet, jeder mit einem anderen Klassenlabel, das durch eine klare Lücke voneinander getrennt ist. Neue Datenpunkte werden dann in denselben Raum abgebildet und als Teil einer Klasse vorhergesagt, je nachdem, auf welcher Seite der Lücke sie liegen. SVM kann aber auch nicht-lineare Klassifikationen durchführen. Nebst der Robustheit gegenüber Überanpassung liegt der Vorteil in der Effektivität in hochdimensionalen Räumen (also wenn die Anzahl der Merkmale größer als die Anzahl an Beobachtungen ist). Durch verschiedene Kernel-Funktionen (darunter linear, polynominal und sigmoid) sind SVMs flexibel auf verschiedene Datensätze und Problemtypen einsetzbar. Allerdings gestaltet sich die Modellauswahl mitunter durch das Hyperparameter-Tuning und die Kernel-Auswahl als komplex. Unter der Modellkomplexität leidet ebenfalls die Interpretierbarkeit (Cortes und Vapnik 1995)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen und trainieren des SVM Modells \n",
    "svm = SVC(kernel='rbf', C=1.0, probability=True, random_state=42)\n",
    "svm.fit(X_resampled, y_resampled)\n",
    "evaluation(svm, X_resampled,  y_resampled, X_test, y_test, train=True)\n",
    "evaluation(svm, X_resampled,  y_resampled, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verwendeter Kern: rbf - Auch als Gaussian Kernel bezeichnet, misst er die Ähnlichkeit der Datenpunkte, indem er den euklidischen Abstand in den exponentiellen Term einbezieht. Das dieser Kern besonders effektiv bei komplexen und nichtlinearen Mustern ist, ist er im Falle dieses Datensatzes geeignet. \n",
    "\n",
    "PCA wird angewendet, um die Dimensionen des hochdimensionalen HR-Datensatzes zu reduzieren, der 40 Merkmale umfasst. Diese Technik transformiert die Daten in einen kleineren Raum (z. B. 2D), indem sie die Hauptkomponenten wählt, die die meiste Varianz erklären. Dies erleichtert die Visualisierung und Interpretation des Modells, insbesondere bei der Darstellung von Entscheidungsgrenzen des SVM-Modells in zwei Dimensionen. Außerdem hilft PCA, irrelevante oder korrelierte Merkmale zu entfernen, was die Effizienz und Performance des Modells verbessern kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_resampled) \n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o')\n",
    "plt.xlabel('Anzahl der Hauptkomponenten')\n",
    "plt.ylabel('Kumulierte erklärte Varianz')\n",
    "plt.title('Varianz erklärt durch PCA')\n",
    "plt.axhline(y=0.9, color='r', linestyle='--', label='90% Varianz')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA-Komponenten und ihre Bedeutung für die ursprünglichen Features\n",
    "components = pca.components_\n",
    "features = X_resampled.columns  # Namen der Features\n",
    "\n",
    "# Ausgabe der ersten zwei Hauptkomponenten\n",
    "for i in range(2):  # oder die Anzahl der gewünschten Komponenten\n",
    "    component = components[i]\n",
    "    feature_importance = sorted(zip(features, component), key=lambda x: abs(x[1]), reverse=True)\n",
    "    print(f\"Hauptkomponente {i + 1}:\")\n",
    "    for feature, importance in feature_importance:\n",
    "        print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionsreduktion mit PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_resampled)\n",
    "\n",
    "# Trainieren des SVM-Modells auf den reduzierten Daten\n",
    "svm_pca = SVC(kernel='rbf', C=1.0, probability=True, random_state=42)\n",
    "svm_pca.fit(X_pca, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung der Entscheidungsgrenzen\n",
    "def plot_decision_boundary(X, y, model, title='Entscheidungsgrenze'):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 8),\n",
    "                         np.arange(y_min, y_max, 8))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.viridis)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o', cmap=plt.cm.viridis)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Merkmal 1')\n",
    "    plt.ylabel('Merkmal 2')\n",
    "    plt.show()\n",
    "\n",
    "# Plot der Entscheidungsgrenzen\n",
    "plot_decision_boundary(X_pca, y_resampled, svm_pca, title='Entscheidungsgrenzen des SVM auf PCA-reduzierten Daten')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(svm_pca, X_pca,  y_resampled, X_test, y_test, train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das PCA-Reduzierte Datenset verbessert die Ergebnisse des Modells nicht.  \n",
    "Mithilfe von GridSearch wird nun eine geeignete Parameterkombination identifiziert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(random_state=42)\n",
    "\n",
    "param_grid = [\n",
    "    {'C': [0.1, 1, 6, 10], 'gamma': [0.001, 0.005, 0.01], 'kernel': ['rbf']},\n",
    "]\n",
    "\n",
    "\n",
    "search = GridSearchCV(svm, param_grid=param_grid, scoring='roc_auc', cv=3, refit=True, verbose=1)\n",
    "search.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei mehrmaligem Testen mit unterschiedlichen RandomStates wird deutlich, dass die geeigneten Parameterkombinationen stark voneinander abweichen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(**search.best_params_, probability=True)\n",
    "svm.fit(X_resampled, y_resampled)\n",
    "\n",
    "evaluation(svm, X_resampled,  y_resampled, X_test, y_test, train=True)\n",
    "evaluation(svm, X_resampled,  y_resampled, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualisierung der Modellperformance\n",
    "\n",
    "Die *ROC-Curve* (Receiver Operating Characteristic) ist ein Tool zur Bewertung der Leistung eines binären Klassifikationsmodells. Sie stellt die wahre positive Rate (True Positive Rate, TPR) gegenüber der falschen positiven Rate (False Positive Rate, FPR) dar, um die Trennschärfe des Modells bei verschiedenen Schwellenwerten zu visualisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_svm, tpr_svm, _ = roc_curve(y_test, svm.predict(X_test))\n",
    "roc_auc_svm = roc_auc_score(y_test, svm.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotten der ROC-Kurve für SVM\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fpr_svm, tpr_svm, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_svm:0.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve SVM')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vergleich der Methoden \n",
    "Im Folgenden werden die zuvor angewendeten Modelle SVM, XGBoost und Random Forest verglichen um zu bewerten, welches Modell die besten Ergebnisse liefert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotten der ROC-Kurven der verschiedenen Modelle\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# ROC-Kurve vor dem Tuning\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(fpr_svm, tpr_svm, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_svm:0.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve SVM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# ROC-Kurve XGBoost\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(fpr_xgb_model_2, tpr_xgb_model_2, color='darkorange', lw=2, label=f'ROC curve original (area = {auc:0.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC XGBoost')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# ROC-Kurve Random Forest\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(fpr_rf, tpr_rf, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_rf:0.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Random Forest')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erklärung der Vorhersagen mittels SHAP\n",
    "\n",
    "SHapley Additive exPlanations (SHAP) ist eine Methode zur Erklärung der Vorhersagen von Machine-Learning-Modellen. In XGBoost wird SHAP verwendet, um die Beitrage einzelner Merkmale zu den Modellvorhersagen zu quantifizieren und zu visualisieren. \n",
    "\n",
    "SHAP-Werte quantifizieren den Einfluss jedes Merkmals auf die Modellvorhersage.\n",
    "Mit SHAP können verschiedene Plots erstellt werden, um die Bedeutung und den Einfluss der Merkmale zu visualisieren.\n",
    "\n",
    "- Im *Summary Plot* sind die Merkmale nach Bedeutung sortiert. Die X-Achse zeigt den Einfluss des Merkmals auf die Vorhersage. \n",
    "Postive Werte bedeuten, dass das Merkmal die Wahrscheinlichkeit erhöht, dass das Modell eine positive Klasse vorhersagt. Negative Werte bedeuten, dass das Merkmal diese Wahrscheinlichkeit verringert. \n",
    "Die Farbe repräsentiert den Wert des Merkmales (rot hohe Werte, blau niedrige Werte)\n",
    "\n",
    "- Ein *Dependence Plot* zeigt die Beziehung zwischen den SHAP-Werten eines bestimmten Merkmals und den Werten dieses Merkmals selbst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung SHAP explainer\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Summary Plot\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "\n",
    "# Dependence plot für das Merkmal \"Monthly Income\"\n",
    "shap.dependence_plot('MonthlyIncome', shap_values, X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
